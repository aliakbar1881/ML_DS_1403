{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EX1)The fundamental idea behind Support Vector Machines is to fit the widest possible “street” between the classes. In other words, the goal is to have the largest possible margin between the decision boundary that separates the two classes and the training instances. When performing soft margin classification, the SVM searches for a compromise between perfectly separating the two classes and having the widest possible street (i.e., a few instances may end up on the street). Another key idea is to use kernels when training on nonlinear datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EX2)After training an SVM, a support vector is any instance located on the “street”, including its border. The decision boundary is entirely determined by the support vectors. Any instance that is not a support vector (i.e., is off the street) has no influence whatsoever; you could remove them, add more instances, or move them around, and as long as they stay off the street they won’t affect the decision boundary. Computing the predictions only involves the support vectors, not the whole training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EX3)SVMs try to fit the largest possible “street” between the classes (see the first answer), so if the training set is not scaled, the SVM will tend to neglect(بی توجهی) small features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EX4)An SVM classifier can output the distance between the test instance and the decision boundary, and you can use this as a confidence score.\n",
    "یک SVM به صورت مستقیم نمی‌تواند احتمال تولید کند\n",
    "با استفاده از روش‌هایی مانند کالیبراسیون احتمال (Probability Calibration)، می‌توان احتمال‌ها را محاسبه کرد.\n",
    "یکی از روش‌های رایج کالیبراسیون پلات (Platt Scaling) است\n",
    "این روش یک مدل لجستیک رگرسیون روی خروجی تابع تصمیم SVM اعمال می‌کند تا احتمال پیش‌بینی تولید شود.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EX5)\n",
    "This question applies only to linear SVMs since kernelized SVMs can only use the dual form. The computational complexity of the primal form of the SVM problem is proportional to the number of training instances m, while the computational complexity of the dual form is proportional to a number between m and m . So if there are millions of instances, you should definitely use the primal form, because the dual form will be much too slow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EX6)\n",
    "increase gamma or C"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
