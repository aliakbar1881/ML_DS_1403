1. ایده اساسی پشت ماشین های بردار پشتیبانی چیست؟
ایده اساسی پشت ماشین های بردار پشتیبانی این است که وسیع ترین "خیابان" را بین کلاس ها قرار دهیم. به عبارت دیگر، هدف این است که بیشترین حاشیه احتمالی بین مرز تصمیمی که دو کلاس و نمونه های آموزشی را از هم جدا می کند، داشته باشیم.

 2. بردار پشتیبانی چیست؟
پس از آموزش یک SVM، یک بردار پشتیبانی هر نمونه ای است که در "خیابان" قرار دارد ، از جمله حاشیه آن. مرز تصمیم گیری به طور کامل توسط بردارهای پشتیبانی تعیین می شود و محاسبه پیش بینی ها فقط شامل بردارهای پورت پشتیبانی می شود، نه کل مجموعه آموزشی.

 3. چرا مقیاس بندی ورودی ها هنگام استفاده از SVM مهم است؟ 
SVM ها سعی می کنند بزرگترین "خیابان" ممکن را بین کلاس ها قرار دهند، بنابراین اگر مجموعه آموزشی مقیاس بندی نشود، SVM تمایل دارد از ویژگی های کوچک غافل شود.

4. آیا یک طبقه بندی کننده SVM می تواند هنگام طبقه بندی یک نمونه امتیاز اطمینان را تولید کند؟ در مورد احتمال چطور؟
یک طبقه بندی کننده SVM می تواند فاصله بین نمونه آزمایشی و مرز تصمیم را خروجی دهد و ما می توانیم از آن به عنوان نمره اطمینان استفاده کنیم. با این حال، این امتیاز را نمی توان مستقیما به تخمین احتمال کلاس تبدیل کرد. اگر هنگام ایجاد یک SVM در Scikit-Learn probability=True را تنظیم کنید، پس از آموزش، احتمالات را با استفاده از رگرسیون لجستیک بر روی نمرات SVM کالیبره می کند (که با اعتبار سنجی متقابل پنج برابری اضافی بر روی داده های آموزشی آموزش داده می شود). با این کار متدهای predict_proba() و predict_log_proba() به SVM اضافه می شود.

 5. آیا باید از فرم اولیه یا دوگانه مسئله SVM برای آموزش یک مدل در یک مجموعه آموزشی با میلیون ها نمونه و صدها ویژگی استفاده کنید؟
این سوال فقط در مورد SVM های خطی صدق می کند زیرا SVM های هسته‌ای فقط می توانند از فرم دوگانه استفاده کنند. و از فرم اولیه مسئله را حل می‌کنیم زیرا پیچیدگی زمانی آن از O(n*m) است ولی پیچیدگی زمانی دوگانه آن از O(n*m^2) یا O(n*m^3) می‌باشد.

 6. فرض کنید یک طبقه بندی کننده SVM را با هسته RBF آموزش داده اید، اما به نظر می رسد که مجموعه آموزشی را برآورده نمی کند. آیا باید γ (گاما) را افزایش یا کاهش دهید؟ در مورد C چطور؟
اگر یک طبقه بندی کننده SVM آموزش دیده با هسته RBF با مجموعه آموزش مطابقت نداشته باشد، ممکن است منظم سازی بیش از حد وجود داشته باشد. برای کاهش آن ، باید گاما یا C (یا هر دو) را افزایش دهید.
 7. چگونه باید پارامترهای QP (H، f، A و b) را برای حل مسئله طبقه بندی کننده SVM خطی حاشیه نرم با استفاده از یک حل کننده QP خارج از قفسه تنظیم کنید؟
Np=1+m+n
Nc=2m
H= یک ماتریس صفر Np * Np است که دارایه (0, 0) آن برابر H' 
f= یک بردار که همه مقادیر آن برابر c می‌باشد
b= یک بردار Nc بعدی که همه مقادیر آن برابر صفر می‌باشد
A= یک ماتریس m*m است
 